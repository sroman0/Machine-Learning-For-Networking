{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "426a8016",
   "metadata": {},
   "source": [
    "<center><b><font size=6>Lab-6 A classifier from scratch<b><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39139f5",
   "metadata": {},
   "source": [
    "### Objective: Implement, use and evaluate a classifier (without using specific libraries such as sklearn)\n",
    "1. **Logistic regression** is a binary classification method that maps a linear combination of parameters and variables into two possible classes. Here, you will implement the logistic regression from scratch to better understand how an ML algorithm works. Useful link: <a href=\"https://en.wikipedia.org/wiki/Logistic_regression\">Wiki</a>.\n",
    "2. **Performance evaluation metrics** are needed to evaluate the outcome of prediction with respect to true labels. Here, you will implement confusion matrix, accuracy, precision, recall and F-measure. Useful link: <a href=\"https://en.wikipedia.org/wiki/Confusion_matrix\">Wiki</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6bf32f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed python libraries\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0959af0",
   "metadata": {},
   "source": [
    "### 1. Dataset - TCP logs\n",
    "The dataset contains traffic information generated by an open-source passive network monitoring tool, namely **tstat**. It automates the collection of packet statistics of traffic aggregates, using real-time monitoring features. Being a passive tool, the typical usage scenario is live monitoring of Internet links, in which all transmitted packets are observed. In case of TCP, Tstat identifies a new flow start when it observes a TCP three-way handshake. Similarly, it identifies a TCP flow end either when it sees the TCP connection teardown, or when it doesnâ€™t observe packets for some time (idle time). A flow is defined by a unique link between the sender and receiver, e.g., a tuple of <em>(IP_Protocol_Type, IP_Source_Address, Source_Port, IP_Destination_Address, Destination_Port)</em>. For a specific flow, tstat calculates a number of statistics of all the packets transmitted over this flow, and then generate a log for such flow with multiple attributes (statistics). A log file is arranged as a simple table where each column is associated to specific information and each row reports the flow during a connection. The log information is a summary of the flow properties. For instance, in the TCP log we can find columns like the starting time of a TCP connection, its duration, the number of sent and received packets, the observed Round Trip Time.\n",
    "![](tstat.png)\n",
    "\n",
    "In this lab, since the focus is on the development of logistic regression from scratch, we only consider a portion of the dataset for simplicity. The data can be found in `log_tcp_part.csv`, in which there are multiple columns, the last one is the class label, indicating the flow is from either **google** or **youtube**, and the rest are features. Your job is a binary classification task to classify the domain of each flow (row) **from scratch**, including:\n",
    "- Build a logistic regression model,\n",
    "- Evaluate the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc1d837",
   "metadata": {},
   "source": [
    "1. Load the dataset.\n",
    "2. Get the list of features (columns 1 to 10).\n",
    "3. Add a new column and assign numerical class labels of -1 and 1 to google and youtube.\n",
    "4. Answering the following questions:\n",
    "    - How many features do we have? 10\n",
    "    - How many samples do we have in total? 20000\n",
    "    - How many samples do we have for each class? Are they similar? 10000 10000, they are equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70294ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_msgsize_count</th>\n",
       "      <th>c_pktsize6</th>\n",
       "      <th>c_msgsize4</th>\n",
       "      <th>s_msgsize4</th>\n",
       "      <th>s_pktsize2</th>\n",
       "      <th>s_rtt_cnt</th>\n",
       "      <th>s_rtt_std</th>\n",
       "      <th>s_msgsize5</th>\n",
       "      <th>c_msgsize6</th>\n",
       "      <th>c_sit3</th>\n",
       "      <th>class</th>\n",
       "      <th>M_classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1418</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>google</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.466732</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>google</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.413304</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>google</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1418</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>google</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1418</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>google</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>1418</td>\n",
       "      <td>3</td>\n",
       "      <td>22.224528</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.334</td>\n",
       "      <td>youtube</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>57</td>\n",
       "      <td>1418</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>1.252</td>\n",
       "      <td>youtube</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1205</td>\n",
       "      <td>0</td>\n",
       "      <td>531</td>\n",
       "      <td>4</td>\n",
       "      <td>15.323660</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4975.694</td>\n",
       "      <td>youtube</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>690</td>\n",
       "      <td>0</td>\n",
       "      <td>767</td>\n",
       "      <td>4</td>\n",
       "      <td>17.997651</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1719.125</td>\n",
       "      <td>youtube</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>youtube</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       c_msgsize_count  c_pktsize6  c_msgsize4  s_msgsize4  s_pktsize2  \\\n",
       "0                    1           0           0           0        1418   \n",
       "1                    1           0           0           0           0   \n",
       "2                    1           0           0           0           0   \n",
       "3                    1           0           0           0        1418   \n",
       "4                    1           0           0           0        1418   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "19995                4           0          37           0        1418   \n",
       "19996                6          45          45          57        1418   \n",
       "19997                4           0        1205           0         531   \n",
       "19998                4           0         690           0         767   \n",
       "19999                1           0           0           0           0   \n",
       "\n",
       "       s_rtt_cnt  s_rtt_std  s_msgsize5  c_msgsize6    c_sit3    class  \\\n",
       "0              0   0.000000           0           0     0.000   google   \n",
       "1              3   0.466732           0           0     0.000   google   \n",
       "2              3   0.413304           0           0     0.000   google   \n",
       "3              1   0.000000           0           0     0.000   google   \n",
       "4              0   0.000000           0           0     0.000   google   \n",
       "...          ...        ...         ...         ...       ...      ...   \n",
       "19995          3  22.224528           0           0     3.334  youtube   \n",
       "19996          2   0.000000          45          45     1.252  youtube   \n",
       "19997          4  15.323660           0           0  4975.694  youtube   \n",
       "19998          4  17.997651           0           0  1719.125  youtube   \n",
       "19999          1   0.000000           0           0     0.000  youtube   \n",
       "\n",
       "       M_classes  \n",
       "0             -1  \n",
       "1             -1  \n",
       "2             -1  \n",
       "3             -1  \n",
       "4             -1  \n",
       "...          ...  \n",
       "19995          1  \n",
       "19996          1  \n",
       "19997          1  \n",
       "19998          1  \n",
       "19999          1  \n",
       "\n",
       "[20000 rows x 12 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your answers here\n",
    "dataframe = pd.read_csv('log_tcp_part.csv')\n",
    "features = dataframe.columns\n",
    "dataframe ['M_classes'] = np.where(dataframe['class'] == 'google', -1, 1)\n",
    "dataframe ['class'].value_counts()\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c8cc80",
   "metadata": {},
   "source": [
    "### 2. Implement your logistic regression learning algorithm\n",
    "Here you will need to construct a class in which you need to define two functions besides the class initialization:\n",
    "- `fit`. In this method you will perform ERM. Learn the parameters of the model (i.e., the hypothesis h) from training with gradient descent\n",
    "- `predict`. In this method given one  sample x (or more) you will perform the inference $sign(h(x))$ to obtain class labels.\n",
    "\n",
    "Hints:\n",
    "\n",
    "- The linear function used in the logistic regression is the following: $h(x)=w^T x +b $, where b is a scalar bias.\n",
    "- Logistic loss: $L((x,y),h)=\\log(1+e^{-y h(x)})$\n",
    "- ERM: $\\min_{w,b} f(w,b)=\\frac{1}{m}\\sum_{i=1}^{m} \\log(1+e^{-y^{(i)} h(x^{(i)})})$\n",
    "- Gradient for weight: $\\nabla_w f(w,b) = \\frac{1}{m} \\sum_i \\frac{-y^{(i)}x^{(i)}}{(1+e^{-y^{(i)}h(x^{(i)})})}$\n",
    "- Gradient for bias: $\\nabla_b f(w,b)= \\frac{1}{m} \\sum_i \\frac{-y^{(i)}}{(1+e^{-y^{(i)}h(x^{(i)})})}$\n",
    "- Update the parameters: $w \\leftarrow w - \\alpha \\nabla w$, $b \\leftarrow b - \\alpha  \\nabla b$\n",
    "\n",
    "Notice that the sigmoid function $f(z) = \\frac{1}{1 + e^{-z}}$ appears multiple times. You can write also a method for the sigmoid function to help you in the computation. By considering f(z), the gradients rewrite as:\n",
    "\n",
    "- Gradient for weight: $\\nabla_w f(w,b) = \\frac{1}{m} \\sum_i ({f(h(x^{(i)})) - y^{(i)}})x^{(i)}$\n",
    "- Gradient for bias: $\\nabla_b f(w,b) = \\frac{1}{m} \\sum_i ({f(h(x^{(i)})) - y^{(i)}})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f97beaef-84d5-48b2-a3a9-2d5ad6dbc049",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataframe.iloc[:,0:10]\n",
    "\n",
    "y = dataframe.iloc[:,11]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90a02f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    \n",
    "    def __init__(self, learning_rate, num_iterations):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iterations = num_iterations\n",
    "        self.b = None\n",
    "        self.W = None\n",
    "        self.ER = None\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1/(1 + np.exp(-z))\n",
    "        \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.b = 0\n",
    "        # Define the range\n",
    "        low, high = -1, 1  # for example, between -1 and 1\n",
    "\n",
    "        # Generate a random vector of 10 values within the range\n",
    "        self.W = np.random.uniform(low, high, 10)\n",
    "        self.ER = 0\n",
    "        \n",
    "        for i in range(self.num_iterations):\n",
    "            \n",
    "            z = X.dot(self.W) + self.b\n",
    "            \n",
    "            sigmoide = self.sigmoid(z)\n",
    "            \n",
    "            loss = np.log(1 + np.exp(-y * z))\n",
    "            ER = (1/len(y))*np.sum(loss)\n",
    "            \n",
    "            if(ER < self.ER):\n",
    "                self.ER = ER\n",
    "                dw = (1/len(y))*np.dot(X.T, (sigmoide-y))\n",
    "                db = (1/len(y))*np.sum(sigmoide-y)\n",
    "                self.W -= dw*self.learning_rate\n",
    "                self.b -= db*self.learning_rate\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \n",
    "        lista_labels = []\n",
    "        \n",
    "        for index,element in X.iterrows():\n",
    "            \n",
    "            \n",
    "            z = element.dot(self.W) + self.b\n",
    "            sigmoide = self.sigmoid(z)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            if sigmoide > 0.5:\n",
    "                lista_labels = lista_labels + [1]\n",
    "            else:\n",
    "                lista_labels = lista_labels + [-1]\n",
    "                \n",
    "        return lista_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc478b78",
   "metadata": {},
   "source": [
    "### 3. Use the model\n",
    "- Initialize your model with predefined learning rate of `0.1` and iterations of `100`.\n",
    "- Fit your model with features and targets.\n",
    "- Get the prediction with features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af5a590d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/arraylike.py:364: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: overflow encountered in exp\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression(0.1, 100)\n",
    "\n",
    "\n",
    "x_test = X[9900:10800]\n",
    "y_true = y[9900:10800]\n",
    "\n",
    "classifier.fit(X,y)\n",
    "\n",
    "\n",
    "\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5ad9e7",
   "metadata": {},
   "source": [
    "### 4. Model evaluation\n",
    "With predicted class labels and ground truths, we now evaluate the model performance through confusion matrix and numerical metrics. Specifically, you need to derive the following:\n",
    "- Confusion matrix - Note that, you should indicate the corresponding quantity of each element in the table. Here positive is class 1 and negative is class -1:\n",
    "\\begin{array}{|c|c|c|}\n",
    "\\hline\n",
    " & \\textbf{Predicted Positive} & \\textbf{Predicted Negative} \\\\\n",
    "\\hline\n",
    "\\textbf{Actual Positive} & \\text{True Positive (TP)} & \\text{False Negative (FN)} \\\\\n",
    "\\hline\n",
    "\\textbf{Actual Negative} & \\text{False Positive (FP)} & \\text{True Negative (TN)} \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "- Precision of each class and the average value:\n",
    "$\\frac{\\text{True Positive (TP)}}{\\text{True Positive (TP) + False Positive (FP)}}$\n",
    "- Recall of each class and the average value:\n",
    "$\\frac{\\text{True Positive (TP)}}{\\text{True Positive (TP) + False Negative (FN)}}$\n",
    "- F1-score of each class and the average value:\n",
    "$F_1 = \\frac{2 \\times \\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}$\n",
    "- Accuracy:\n",
    "$\\frac{\\text{True Positive (TP) + True Negative (TN)}}{\\text{True Positive (TP) + True Negative (TN) + False Positive (FP) + False Negative (FN)}}$\n",
    "- Answering the following questions:\n",
    "    - Do you have same performance between classes? If not, which one performs better?\n",
    "    - Change the parameters of learning rate or number of iterations. Do you have same performance? Better or Worse? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15b74982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "TP: 627, FP: 95, FN: 173, TN: 5\n",
      "\n",
      "Metrics:\n",
      "Precision (Positive Class): 0.868421052631579\n",
      "Precision (Negative Class): 0.028089887640449437\n",
      "Average Precision: 0.4482554701360142\n",
      "Recall (Positive Class): 0.78375\n",
      "Recall (Negative Class): 0.05\n",
      "Average Recall: 0.416875\n",
      "F1-Score (Positive Class): 0.8239159001314061\n",
      "F1-Score (Negative Class): 0.03597122302158273\n",
      "Average F1-Score: 0.42994356157649444\n",
      "Accuracy: 0.7022222222222222\n"
     ]
    }
   ],
   "source": [
    "# Initialize confusion matrix elements\n",
    "tp = fp = fn = tn = 0\n",
    "\n",
    "# Compute TP, FP, FN, and TN\n",
    "for actual, predicted in zip(y_true, y_pred):\n",
    "    if actual == 1 and predicted == 1:\n",
    "        tp += 1  # True Positive\n",
    "    elif actual == -1 and predicted == 1:\n",
    "        fp += 1  # False Positive\n",
    "    elif actual == 1 and predicted == -1:\n",
    "        fn += 1  # False Negative\n",
    "    elif actual == -1 and predicted == -1:\n",
    "        tn += 1  # True Negative\n",
    "\n",
    "# Precision, Recall, F1-Score, and Accuracy calculations\n",
    "precision_pos = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "precision_neg = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "recall_pos = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "recall_neg = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "# Average precision and recall\n",
    "precision_avg = (precision_pos + precision_neg) / 2\n",
    "recall_avg = (recall_pos + recall_neg) / 2\n",
    "\n",
    "# F1-Scores\n",
    "f1_pos = (2 * precision_pos * recall_pos) / (precision_pos + recall_pos) if (precision_pos + recall_pos) > 0 else 0\n",
    "f1_neg = (2 * precision_neg * recall_neg) / (precision_neg + recall_neg) if (precision_neg + recall_neg) > 0 else 0\n",
    "f1_avg = (f1_pos + f1_neg) / 2\n",
    "\n",
    "# Accuracy\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "# Print the results\n",
    "print(\"Confusion Matrix:\")\n",
    "print(f\"TP: {tp}, FP: {fp}, FN: {fn}, TN: {tn}\")\n",
    "print(\"\\nMetrics:\")\n",
    "print(f\"Precision (Positive Class): {precision_pos}\")\n",
    "print(f\"Precision (Negative Class): {precision_neg}\")\n",
    "print(f\"Average Precision: {precision_avg}\")\n",
    "print(f\"Recall (Positive Class): {recall_pos}\")\n",
    "print(f\"Recall (Negative Class): {recall_neg}\")\n",
    "print(f\"Average Recall: {recall_avg}\")\n",
    "print(f\"F1-Score (Positive Class): {f1_pos}\")\n",
    "print(f\"F1-Score (Negative Class): {f1_neg}\")\n",
    "print(f\"Average F1-Score: {f1_avg}\")\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "426a8016",
   "metadata": {},
   "source": [
    "<center><b><font size=6>Lab-6 A classifier from scratch<b><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39139f5",
   "metadata": {},
   "source": [
    "### Objective: Implement, use and evaluate a classifier (without using specific libraries such as sklearn)\n",
    "1. **Logistic regression** is a binary classification method that maps a linear combination of parameters and variables into two possible classes. Here, you will implement the logistic regression from scratch to better understand how an ML algorithm works. Useful link: <a href=\"https://en.wikipedia.org/wiki/Logistic_regression\">Wiki</a>.\n",
    "2. **Performance evaluation metrics** are needed to evaluate the outcome of prediction with respect to true labels. Here, you will implement confusion matrix, accuracy, precision, recall and F-measure. Useful link: <a href=\"https://en.wikipedia.org/wiki/Confusion_matrix\">Wiki</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6bf32f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed python libraries\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0959af0",
   "metadata": {},
   "source": [
    "### 1. Dataset - TCP logs\n",
    "The dataset contains traffic information generated by an open-source passive network monitoring tool, namely **tstat**. It automates the collection of packet statistics of traffic aggregates, using real-time monitoring features. Being a passive tool, the typical usage scenario is live monitoring of Internet links, in which all transmitted packets are observed. In case of TCP, Tstat identifies a new flow start when it observes a TCP three-way handshake. Similarly, it identifies a TCP flow end either when it sees the TCP connection teardown, or when it doesnâ€™t observe packets for some time (idle time). A flow is defined by a unique link between the sender and receiver, e.g., a tuple of <em>(IP_Protocol_Type, IP_Source_Address, Source_Port, IP_Destination_Address, Destination_Port)</em>. For a specific flow, tstat calculates a number of statistics of all the packets transmitted over this flow, and then generate a log for such flow with multiple attributes (statistics). A log file is arranged as a simple table where each column is associated to specific information and each row reports the flow during a connection. The log information is a summary of the flow properties. For instance, in the TCP log we can find columns like the starting time of a TCP connection, its duration, the number of sent and received packets, the observed Round Trip Time.\n",
    "![](tstat.png)\n",
    "\n",
    "In this lab, since the focus is on the development of logistic regression from scratch, we only consider a portion of the dataset for simplicity. The data can be found in `log_tcp_part.csv`, in which there are multiple columns, the last one is the class label, indicating the flow is from either **google** or **youtube**, and the rest are features. Your job is a binary classification task to classify the domain of each flow (row) **from scratch**, including:\n",
    "- Build a logistic regression model,\n",
    "- Evaluate the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc1d837",
   "metadata": {},
   "source": [
    "1. Load the dataset.\n",
    "2. Get the list of features (columns 1 to 10).\n",
    "3. Add a new column and assign numerical class labels of -1 and 1 to google and youtube.\n",
    "4. Answering the following questions:\n",
    "    - How many features do we have?\n",
    "    - How many samples do we have in total?\n",
    "    - How many samples do we have for each class? Are they similar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70294ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answers here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c8cc80",
   "metadata": {},
   "source": [
    "### 2. Implement your logistic regression learning algorithm\n",
    "Here you will need to construct a class in which you need to define two functions besides the class initialization:\n",
    "- `fit`. In this method you will perform ERM. Learn the parameters of the model (i.e., the hypothesis h) from training with gradient descent\n",
    "- `predict`. In this method given one  sample x (or more) you will perform the inference $sign(h(x))$ to obtain class labels.\n",
    "\n",
    "Hints:\n",
    "\n",
    "- The linear function used in the logistic regression is the following: $h(x)=w^T x +b $, where b is a scalar bias.\n",
    "- Logistic loss: $L((x,y),h)=\\log(1+e^{-y h(x)})$\n",
    "- ERM: $\\min_{w,b} f(w,b)=\\frac{1}{m}\\sum_{i=1}^{m} \\log(1+e^{-y^{(i)} h(x^{(i)})})$\n",
    "- Gradient for weight: $\\nabla_w f(w,b) = \\frac{1}{m} \\sum_i \\frac{-y^{(i)}x^{(i)}}{(1+e^{-y^{(i)}h(x^{(i)})})}$\n",
    "- Gradient for bias: $\\nabla_b f(w,b)= \\frac{1}{m} \\sum_i \\frac{-y^{(i)}}{(1+e^{-y^{(i)}h(x^{(i)})})}$\n",
    "- Update the parameters: $w \\leftarrow w - \\alpha \\nabla w$, $b \\leftarrow b - \\alpha  \\nabla b$\n",
    "\n",
    "Notice that the sigmoid function $f(z) = \\frac{1}{1 + e^{-z}}$ appears multiple times. You can write also a method for the sigmoid function to help you in the computation. By considering f(z), the gradients rewrite as:\n",
    "\n",
    "- Gradient for weight: $\\nabla_w f(w,b) = \\frac{1}{m} \\sum_i ({f(h(x^{(i)})) - y^{(i)}})x^{(i)}$\n",
    "- Gradient for bias: $\\nabla_b f(w,b) = \\frac{1}{m} \\sum_i ({f(h(x^{(i)})) - y^{(i)}})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a02f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate, num_iterations):\n",
    "        # your answers here\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        # your answers here\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # your answers here\n",
    "\n",
    "    def predict(self, X):\n",
    "        # your answers here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc478b78",
   "metadata": {},
   "source": [
    "### 3. Use the model\n",
    "- Initialize your model with predefined learning rate of `0.1` and iterations of `100`.\n",
    "- Fit your model with features and targets.\n",
    "- Get the prediction with features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5a590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answers here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5ad9e7",
   "metadata": {},
   "source": [
    "### 4. Model evaluation\n",
    "With predicted class labels and ground truths, we now evaluate the model performance through confusion matrix and numerical metrics. Specifically, you need to derive the following:\n",
    "- Confusion matrix - Note that, you should indicate the corresponding quantity of each element in the table. Here positive is class 1 and negative is class -1:\n",
    "\\begin{array}{|c|c|c|}\n",
    "\\hline\n",
    " & \\textbf{Predicted Positive} & \\textbf{Predicted Negative} \\\\\n",
    "\\hline\n",
    "\\textbf{Actual Positive} & \\text{True Positive (TP)} & \\text{False Negative (FN)} \\\\\n",
    "\\hline\n",
    "\\textbf{Actual Negative} & \\text{False Positive (FP)} & \\text{True Negative (TN)} \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "- Precision of each class and the average value:\n",
    "$\\frac{\\text{True Positive (TP)}}{\\text{True Positive (TP) + False Positive (FP)}}$\n",
    "- Recall of each class and the average value:\n",
    "$\\frac{\\text{True Positive (TP)}}{\\text{True Positive (TP) + False Negative (FN)}}$\n",
    "- F1-score of each class and the average value:\n",
    "$F_1 = \\frac{2 \\times \\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}$\n",
    "- Accuracy:\n",
    "$\\frac{\\text{True Positive (TP) + True Negative (TN)}}{\\text{True Positive (TP) + True Negative (TN) + False Positive (FP) + False Negative (FN)}}$\n",
    "- Answering the following questions:\n",
    "    - Do you have same performance between classes? If not, which one performs better?\n",
    "    - Change the parameters of learning rate or number of iterations. Do you have same performance? Better or Worse? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b74982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answers here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
